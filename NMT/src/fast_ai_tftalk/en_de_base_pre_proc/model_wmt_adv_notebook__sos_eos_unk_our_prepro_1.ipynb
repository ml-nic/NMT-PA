{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "#import sutils; importlib.reload(sutils)\n",
    "from sutils import *\n",
    "\n",
    "import keras\n",
    "import gensim\n",
    "import re\n",
    "import pickle\n",
    "import keras.backend as K\n",
    "\n",
    "from keras import initializers\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, Callback, ReduceLROnPlateau, LearningRateScheduler, EarlyStopping, TensorBoard\n",
    "from keras.callbacks import LambdaCallback\n",
    "\n",
    "\n",
    "from recurrentshop import *\n",
    "import seq2seq\n",
    "from seq2seq.models import AttentionSeq2Seq,SimpleSeq2Seq, Seq2Seq\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras_tqdm import TQDMNotebookCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.8\n",
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "print(keras.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "path = '../neural_translation_en_de/'\n",
    "dpath = '../neural_translation_en_de/translate/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ### Set up Regex and tokenize for use later\n",
    "\n",
    "re_mult_space = re.compile(r\"  *\")\n",
    "re_mw_punc = re.compile(r\"(\\w[’'])(\\w)\")\n",
    "re_punc = re.compile(\"([\\\"().,;:/_?!—])\")\n",
    "re_apos = re.compile(r\"(\\w)'s\\b\")\n",
    "\n",
    "\n",
    "def simple_toks(sent):\n",
    "    sent = re_apos.sub(r\"\\1 's\", sent)\n",
    "    sent = re_mw_punc.sub(r\"\\1 \\2\", sent)\n",
    "    sent = re_punc.sub(r\" \\1 \", sent).replace('-', ' ')\n",
    "    sent = re_mult_space.sub(' ', sent)\n",
    "    return sent.lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ## Load the PreProcessed data\n",
    "# \n",
    "# Here we load all the data \n",
    "\n",
    "data = load(dpath+'nmt_datawmtsmall_sos_eos_unk.pkl')\n",
    "look_ups = load(dpath+'look_upswmtsmall_sos_eos_unk.pkl')\n",
    "fr_train = data['fr_train']\n",
    "fr_test = data['fr_test']\n",
    "en_train = data['en_train']\n",
    "en_test = data['en_test']\n",
    "en_w2id = look_ups['en_w2id']\n",
    "fr_vocab = look_ups['fr_vocab']\n",
    "en_vocab = look_ups['en_vocab']\n",
    "en_embs = look_ups['en_embs']\n",
    "fr_embs = look_ups['fr_embs']\n",
    "\n",
    "questions = load(dpath+'questionswmt.pkl')\n",
    "#print(questions[10])\n",
    "en_qs, fr_qs = zip(*questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 100)\n",
      "(100000, 100)\n"
     ]
    }
   ],
   "source": [
    "print(fr_train.shape)\n",
    "print(en_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ## Model\n",
    "\n",
    "# #### Create some Keras Callbacks to handle early stopping and Learning Rate changes\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "reduce_LR = ReduceLROnPlateau(monitor='val_loss',factor = 0.5, patience=0,cooldown=1, min_lr = 0.00001)\n",
    "early_stopping = EarlyStopping(monitor='val_loss',min_delta=0,patience=4,verbose=0,mode='auto')\n",
    "\n",
    "import math\n",
    "\n",
    "# learning rate schedule for dropping every 10 epochs\n",
    "def LRDropping(epoch):\n",
    "    initial_lrate = 0.001\n",
    "    drop = 0.9\n",
    "    epochs_drop = 3.0\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "# try at manual setting of LR for Epochs\n",
    "def fixed_dropping(epoch):\n",
    "    if epoch < 2: \n",
    "        lrate = 0.01\n",
    "    elif epoch < 4: \n",
    "        lrate = 0.001\n",
    "    elif epoch < 7: \n",
    "        lrate = 0.0005\n",
    "    else:\n",
    "        lrate = 0.0001\n",
    "    print(lrate)\n",
    "    return lrate\n",
    "\n",
    "LRDrop = LearningRateScheduler(fixed_dropping)\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "tbCallBack = TensorBoard(log_dir='/data/model_newGraphadvsmall_sos_eos_unk', write_graph=True)\n",
    "modelCallback = ModelCheckpoint(\n",
    "            'model_checkpoint_advsmall_sos_eos_unk.{epoch:03d}-{loss:.3f}.hdf5',\n",
    "            monitor='val_loss', verbose=1, save_best_only=False,\n",
    "            save_weights_only=True, mode='auto',\n",
    "            period=1)\n",
    "\n",
    "# creating different sets of Params to easily import into the model at train time\n",
    "params = {'verbose': 1, 'callbacks': [TQDMNotebookCallback(),reduce_LR,early_stopping,tbCallBack,modelCallback]}\n",
    "params2 = {'verbose': 1, 'callbacks': [LRDrop,TQDMNotebookCallback(),reduce_LR,early_stopping]}\n",
    "params3 = {'verbose': 1, 'callbacks': [LRDrop,TQDMNotebookCallback(),reduce_LR,early_stopping]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# #### Set some parameters for the model\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "lr = 1e-3\n",
    "maxlen = 100\n",
    "dim_en_vec = 200\n",
    "n_en_vec = 400000\n",
    "dim_fr_vec = 200\n",
    "\n",
    "vocab_size = len(fr_vocab) #the output vocab # embeddings.shape[0]\n",
    "embedding_size = 200 #The english inputs embeddings embeddings.shape[1]\n",
    "\n",
    "\n",
    "fr_wgts = [fr_embs.T, np.zeros((len(fr_vocab,)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 100, 200)          8000600   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 100, 256)          336896    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 100, 256)          394240    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100, 128)          197120    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 100, 200)          25800     \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 100, 40003)        8040603   \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100, 40003)        0         \n",
      "=================================================================\n",
      "Total params: 16,995,259\n",
      "Trainable params: 8,994,659\n",
      "Non-trainable params: 8,000,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ### The model itself\n",
    "\n",
    "# Base Model big\n",
    "inp = Input((maxlen,))\n",
    "x = Embedding(40003, dim_en_vec, input_length=maxlen,\n",
    "              weights=[en_embs], trainable=False)(inp)\n",
    "x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
    "x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
    "x = LSTM(128, return_sequences=True)(x)\n",
    "x = TimeDistributed(Dense(dim_fr_vec))(x)\n",
    "x = TimeDistributed(Dense(40003, weights=fr_wgts))(x)\n",
    "x = Activation('softmax')(x)\n",
    "\n",
    "model = Model(inp, x)\n",
    "model.compile('adam', 'sparse_categorical_crossentropy')\n",
    "\n",
    "\n",
    "K.set_value(model.optimizer.lr, lr)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100000 samples, validate on 10000 samples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a96f943aeb1b4be19756e40524233fd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "586700cf40b1462cac80da87ef8e6ef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 0', max=100000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 99936/100000 [============================>.] - ETA: 0s - loss: 1.9078Epoch 00000: saving model to model_checkpoint_advsmall_sos_eos_unk.000-1.908.hdf5\n",
      "100000/100000 [==============================] - 1191s - loss: 1.9079 - val_loss: 1.7004\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d39aaee8f0d48e4abb17917d65e163b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 1', max=100000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      " 99936/100000 [============================>.] - ETA: 0s - loss: 1.6953Epoch 00001: saving model to model_checkpoint_advsmall_sos_eos_unk.001-1.695.hdf5\n",
      "100000/100000 [==============================] - 1185s - loss: 1.6952 - val_loss: 1.6601\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "633da9ef45ae419e8c10fb98e4303a94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 2', max=100000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      " 99936/100000 [============================>.] - ETA: 0s - loss: 1.6487Epoch 00002: saving model to model_checkpoint_advsmall_sos_eos_unk.002-1.649.hdf5\n",
      "100000/100000 [==============================] - 1186s - loss: 1.6486 - val_loss: 1.6160\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ef7f25030ae4d99913bae54e5a5fe72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 3', max=100000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      " 14976/100000 [===>..........................] - ETA: 987s - loss: 1.6156"
     ]
    }
   ],
   "source": [
    "hist=model.fit(en_train, np.expand_dims(fr_train,axis=-1), batch_size=96, epochs=10, **params, \n",
    "               validation_data=[en_test, np.expand_dims(fr_test,axis=-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_train(hist)\n",
    "for a in hist.history:\n",
    "    print(a, hist.history[a])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_identifier = \"trans_testing_basic_wmt_advsmall_sos_eos_unk\"\n",
    "model.save_weights(dpath + weight_identifier + '.h5')\n",
    "model.load_weights(dpath + weight_identifier + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Testing\n",
    "\n",
    "def sent2ids(sent):\n",
    "    sent = simple_toks(sent)\n",
    "    ids = []\n",
    "    if SOS:\n",
    "        ids.append(en_w2id[\"<SOS>\"])\n",
    "    for t in sent:\n",
    "        try:\n",
    "            ids.append(en_w2id[t])\n",
    "        except KeyError:\n",
    "            if UNK:\n",
    "                ids.append(en_w2id[\"<UNK>\"])\n",
    "            else:\n",
    "                pass\n",
    "    if EOS:\n",
    "        ids.append(en_w2id[\"<EOS>\"])\n",
    "    return pad_sequences([ids], maxlen, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "def en2fr(sent): \n",
    "    ids = sent2ids(sent)\n",
    "    tr_ids = np.argmax(model.predict(ids), axis=-1)\n",
    "    return ' '.join(fr_vocab[i] for i in tr_ids[0] if i>0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en2fr(\"what is the size of canada?\")\n",
    "\n",
    "\n",
    "# In[26]:\n",
    "\n",
    "\n",
    "en2fr(\"what is the size of australia?\")\n",
    "\n",
    "\n",
    "# In[27]:\n",
    "\n",
    "\n",
    "en2fr(\"What is light?\")\n",
    "\n",
    "\n",
    "# In[28]:\n",
    "\n",
    "\n",
    "en2fr(\"Why is the Arctic ozone layer thicker than the Antarctic ozone layer?\")\n",
    "\n",
    "\n",
    "# In[29]:\n",
    "\n",
    "\n",
    "#print(qs[9])\n",
    "en2fr(\"Which province is the most populated?\")\n",
    "\n",
    "\n",
    "# In[30]:\n",
    "\n",
    "\n",
    "en2fr(\"Who are we?\")\n",
    "\n",
    "\n",
    "# In[31]:\n",
    "\n",
    "\n",
    "en2fr(\"What would we do without it?\")\n",
    "\n",
    "\n",
    "# In[32]:\n",
    "\n",
    "\n",
    "en2fr(\"Hello Tom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "source_file = \"C:/Users/Nicolas/CloudStation/PA/DE_EN_(tatoeba)_validation_english_only.txt\"\n",
    "if os.path.exists(source_file) is False:\n",
    "    exit(\"source file does not exists\")\n",
    "\n",
    "source_sentences = open(source_file, encoding='UTF-8').read().split('\\n')\n",
    "print(len(source_sentences))\n",
    "\n",
    "translated_sentences = []\n",
    "i = 0\n",
    "for sent in source_sentences:\n",
    "    if i % int((len(source_sentences) / 100)) == 0:\n",
    "        print(i)\n",
    "    translated_sentences.append(en2fr(sent))\n",
    "    i += 1\n",
    "print(len(translated_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = os.path.join(os.path.abspath(os.path.join(source_file, os.pardir)), weight_identifier + \".pred\")\n",
    "with(open(out_file, 'w', encoding='utf8')) as file:\n",
    "    for sent in translated_sentences:\n",
    "        file.write(sent + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
